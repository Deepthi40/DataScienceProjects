{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "social network ads puchasing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6jWrpJOMHlBo4mn6VHzu0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OItuo8iJIKZI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ithIh8srAbMo"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "mBT70VOzBv9y",
        "outputId": "08052e34-12cd-446e-8293-871bbe8cb06d"
      },
      "source": [
        "df=pd.read_csv('/content/Social_Network_Ads.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15624510</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15810944</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15668575</td>\n",
              "      <td>Female</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15603246</td>\n",
              "      <td>Female</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15804002</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>15691863</td>\n",
              "      <td>Female</td>\n",
              "      <td>46</td>\n",
              "      <td>41000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>15706071</td>\n",
              "      <td>Male</td>\n",
              "      <td>51</td>\n",
              "      <td>23000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>15654296</td>\n",
              "      <td>Female</td>\n",
              "      <td>50</td>\n",
              "      <td>20000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>15755018</td>\n",
              "      <td>Male</td>\n",
              "      <td>36</td>\n",
              "      <td>33000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>15594041</td>\n",
              "      <td>Female</td>\n",
              "      <td>49</td>\n",
              "      <td>36000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
              "0    15624510    Male   19            19000          0\n",
              "1    15810944    Male   35            20000          0\n",
              "2    15668575  Female   26            43000          0\n",
              "3    15603246  Female   27            57000          0\n",
              "4    15804002    Male   19            76000          0\n",
              "..        ...     ...  ...              ...        ...\n",
              "395  15691863  Female   46            41000          1\n",
              "396  15706071    Male   51            23000          1\n",
              "397  15654296  Female   50            20000          1\n",
              "398  15755018    Male   36            33000          0\n",
              "399  15594041  Female   49            36000          1\n",
              "\n",
              "[400 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbeW_FhvCP2a",
        "outputId": "c2efe89c-2e7d-44df-ee03-9e8ddd32c9e2"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "User ID             int64\n",
              "Gender             object\n",
              "Age                 int64\n",
              "EstimatedSalary     int64\n",
              "Purchased           int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EINLohdt69Mo",
        "outputId": "2b3e9255-cbe6-4f39-be96-b4b3f388efbb"
      },
      "source": [
        "df['Gender']=df['Gender'].map({\"Female\":1,\"Male\":0},np.int64)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15624510</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15810944</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15668575</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15603246</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15804002</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
              "0  15624510       0   19            19000          0\n",
              "1  15810944       0   35            20000          0\n",
              "2  15668575       1   26            43000          0\n",
              "3  15603246       1   27            57000          0\n",
              "4  15804002       0   19            76000          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "i8qV8dLFGJpK",
        "outputId": "0568d9c5-d9dc-446c-a2df-6d81fcb8300d"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.scatterplot(x=df['Age'],y=df['Purchased'], ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ-xtWnAKj9A"
      },
      "source": [
        "##From the above and below fig we concluded that who had age b/w 25-50,whose sal is grater than 60,000 are willing to purchase social network ads.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "JXwLHQFi2YNA",
        "outputId": "9be5c0ea-bb4f-4583-d188-3f24a3ddc5c8"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.scatterplot(x=df['EstimatedSalary'],y=df['Purchased'], ax=ax)\n",
        "plt.show()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX_PxsP5L_Fl"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQbFW4hZOB8L",
        "outputId": "afe1adde-a46a-4527-8092-0acc93fbfb25"
      },
      "source": [
        "x=df.drop('Purchased',axis=1,)\n",
        "y=to_categorical(df['Purchased'])\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slIZeEruOfa6",
        "outputId": "3ef020a5-fd68-4936-bcd3-3a192e316619"
      },
      "source": [
        "train_in.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrEUbzY_PCZz"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrohwOnVc9KH"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlgXAbVQPzC0"
      },
      "source": [
        "in_layer=Dense(1)\n",
        "hiddenlayer1=Dense(50)\n",
        "hiddenlayer2=Dense(100)\n",
        "out_layer=Dense(2,activation='Softmax',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYepJRCxPodS"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(in_layer)\n",
        "model.add(hiddenlayer1)\n",
        "model.add(hiddenlayer2)\n",
        "model.add(out_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQDKr1JvQxrL"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avjXRFD8RVkD",
        "outputId": "cc654a68-6d2c-4f0d-e8f7-e276c4d96cbd"
      },
      "source": [
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=350)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4705.8369 - accuracy: 0.5781 - val_loss: 9801.9746 - val_accuracy: 0.3750\n",
            "Epoch 2/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4278.1040 - accuracy: 0.5094 - val_loss: 5100.0132 - val_accuracy: 0.6250\n",
            "Epoch 3/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6952.8530 - accuracy: 0.5719 - val_loss: 11331.9639 - val_accuracy: 0.6250\n",
            "Epoch 4/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4804.6006 - accuracy: 0.5969 - val_loss: 3720.1094 - val_accuracy: 0.3750\n",
            "Epoch 5/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3453.4233 - accuracy: 0.5156 - val_loss: 2110.2922 - val_accuracy: 0.6250\n",
            "Epoch 6/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5978.9023 - accuracy: 0.5031 - val_loss: 11564.1064 - val_accuracy: 0.3750\n",
            "Epoch 7/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11800.5420 - accuracy: 0.5781 - val_loss: 6214.0469 - val_accuracy: 0.3750\n",
            "Epoch 8/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6566.9907 - accuracy: 0.5656 - val_loss: 6878.9404 - val_accuracy: 0.3750\n",
            "Epoch 9/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5819.0308 - accuracy: 0.5406 - val_loss: 7278.9907 - val_accuracy: 0.3750\n",
            "Epoch 10/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3546.1589 - accuracy: 0.5344 - val_loss: 1533.2468 - val_accuracy: 0.6250\n",
            "Epoch 11/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1745.4840 - accuracy: 0.5406 - val_loss: 1998.6832 - val_accuracy: 0.3750\n",
            "Epoch 12/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2768.6721 - accuracy: 0.5219 - val_loss: 3803.9382 - val_accuracy: 0.6250\n",
            "Epoch 13/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2432.0757 - accuracy: 0.4906 - val_loss: 5018.6255 - val_accuracy: 0.6250\n",
            "Epoch 14/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5156.3862 - accuracy: 0.5406 - val_loss: 8126.1455 - val_accuracy: 0.6250\n",
            "Epoch 15/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5444.6260 - accuracy: 0.5656 - val_loss: 6370.7485 - val_accuracy: 0.6250\n",
            "Epoch 16/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4349.5054 - accuracy: 0.5594 - val_loss: 4305.3892 - val_accuracy: 0.6250\n",
            "Epoch 17/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1339.4645 - accuracy: 0.5281 - val_loss: 1463.7434 - val_accuracy: 0.6250\n",
            "Epoch 18/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1651.8480 - accuracy: 0.5656 - val_loss: 1163.5789 - val_accuracy: 0.3750\n",
            "Epoch 19/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2883.0547 - accuracy: 0.5094 - val_loss: 7432.2812 - val_accuracy: 0.6250\n",
            "Epoch 20/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2860.2661 - accuracy: 0.5594 - val_loss: 2665.1653 - val_accuracy: 0.3750\n",
            "Epoch 21/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 991.2889 - accuracy: 0.5531 - val_loss: 1441.3176 - val_accuracy: 0.6250\n",
            "Epoch 22/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3049.8738 - accuracy: 0.5656 - val_loss: 6377.1597 - val_accuracy: 0.6250\n",
            "Epoch 23/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5090.7314 - accuracy: 0.5156 - val_loss: 6501.8765 - val_accuracy: 0.6250\n",
            "Epoch 24/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2983.0117 - accuracy: 0.5656 - val_loss: 1670.9089 - val_accuracy: 0.6250\n",
            "Epoch 25/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3840.6575 - accuracy: 0.5094 - val_loss: 3364.5168 - val_accuracy: 0.6250\n",
            "Epoch 26/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4211.6309 - accuracy: 0.5031 - val_loss: 5338.8037 - val_accuracy: 0.6250\n",
            "Epoch 27/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1903.8582 - accuracy: 0.5781 - val_loss: 606.2018 - val_accuracy: 0.6250\n",
            "Epoch 28/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2485.6294 - accuracy: 0.5344 - val_loss: 2315.5776 - val_accuracy: 0.3750\n",
            "Epoch 29/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2863.5161 - accuracy: 0.5719 - val_loss: 1976.1787 - val_accuracy: 0.6250\n",
            "Epoch 30/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1204.9062 - accuracy: 0.5406 - val_loss: 1182.3020 - val_accuracy: 0.3750\n",
            "Epoch 31/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 564.9730 - accuracy: 0.5469 - val_loss: 1102.9769 - val_accuracy: 0.3750\n",
            "Epoch 32/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 725.4718 - accuracy: 0.4969 - val_loss: 355.7703 - val_accuracy: 0.6250\n",
            "Epoch 33/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1181.0510 - accuracy: 0.5156 - val_loss: 1140.0166 - val_accuracy: 0.3750\n",
            "Epoch 34/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1589.3815 - accuracy: 0.5219 - val_loss: 983.0004 - val_accuracy: 0.6250\n",
            "Epoch 35/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1029.7502 - accuracy: 0.5781 - val_loss: 877.2404 - val_accuracy: 0.3750\n",
            "Epoch 36/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1062.9681 - accuracy: 0.4844 - val_loss: 806.9957 - val_accuracy: 0.6250\n",
            "Epoch 37/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1318.9664 - accuracy: 0.5219 - val_loss: 2186.9685 - val_accuracy: 0.6250\n",
            "Epoch 38/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 804.0057 - accuracy: 0.5969 - val_loss: 679.1672 - val_accuracy: 0.6250\n",
            "Epoch 39/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1282.9988 - accuracy: 0.5719 - val_loss: 1454.9172 - val_accuracy: 0.6250\n",
            "Epoch 40/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 916.1058 - accuracy: 0.5156 - val_loss: 833.8203 - val_accuracy: 0.3750\n",
            "Epoch 41/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 514.1863 - accuracy: 0.5531 - val_loss: 160.0227 - val_accuracy: 0.3750\n",
            "Epoch 42/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 366.4788 - accuracy: 0.5219 - val_loss: 851.2184 - val_accuracy: 0.6250\n",
            "Epoch 43/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 421.1388 - accuracy: 0.5531 - val_loss: 184.9477 - val_accuracy: 0.6250\n",
            "Epoch 44/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 411.3320 - accuracy: 0.5406 - val_loss: 824.2897 - val_accuracy: 0.6250\n",
            "Epoch 45/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 537.8091 - accuracy: 0.6219 - val_loss: 262.7088 - val_accuracy: 0.6250\n",
            "Epoch 46/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 939.4528 - accuracy: 0.5281 - val_loss: 76.9253 - val_accuracy: 0.3750\n",
            "Epoch 47/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 254.0444 - accuracy: 0.5031 - val_loss: 214.1708 - val_accuracy: 0.6250\n",
            "Epoch 48/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 344.2612 - accuracy: 0.5781 - val_loss: 878.9731 - val_accuracy: 0.3750\n",
            "Epoch 49/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 632.0873 - accuracy: 0.5844 - val_loss: 708.4310 - val_accuracy: 0.3750\n",
            "Epoch 50/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 677.7242 - accuracy: 0.5344 - val_loss: 872.8330 - val_accuracy: 0.3750\n",
            "Epoch 51/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 282.1447 - accuracy: 0.5781 - val_loss: 158.5821 - val_accuracy: 0.3750\n",
            "Epoch 52/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 283.0978 - accuracy: 0.5719 - val_loss: 304.9312 - val_accuracy: 0.3750\n",
            "Epoch 53/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 300.5031 - accuracy: 0.5031 - val_loss: 292.0413 - val_accuracy: 0.6250\n",
            "Epoch 54/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 232.2279 - accuracy: 0.5344 - val_loss: 326.3822 - val_accuracy: 0.6250\n",
            "Epoch 55/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 183.4392 - accuracy: 0.5844 - val_loss: 99.4655 - val_accuracy: 0.6250\n",
            "Epoch 56/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 304.9480 - accuracy: 0.4781 - val_loss: 350.5880 - val_accuracy: 0.6250\n",
            "Epoch 57/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 303.0963 - accuracy: 0.5219 - val_loss: 65.9568 - val_accuracy: 0.3750\n",
            "Epoch 58/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 317.9199 - accuracy: 0.5406 - val_loss: 818.8073 - val_accuracy: 0.6250\n",
            "Epoch 59/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 390.2444 - accuracy: 0.5969 - val_loss: 435.3655 - val_accuracy: 0.6250\n",
            "Epoch 60/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 470.2879 - accuracy: 0.5594 - val_loss: 1165.3279 - val_accuracy: 0.6250\n",
            "Epoch 61/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 741.0735 - accuracy: 0.5531 - val_loss: 58.0787 - val_accuracy: 0.3750\n",
            "Epoch 62/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 786.4930 - accuracy: 0.6094 - val_loss: 123.1795 - val_accuracy: 0.3750\n",
            "Epoch 63/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 407.9052 - accuracy: 0.5031 - val_loss: 266.8259 - val_accuracy: 0.6250\n",
            "Epoch 64/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 257.7514 - accuracy: 0.5656 - val_loss: 189.3480 - val_accuracy: 0.6250\n",
            "Epoch 65/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 78.7347 - accuracy: 0.5344 - val_loss: 142.2073 - val_accuracy: 0.6250\n",
            "Epoch 66/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 85.3780 - accuracy: 0.5469 - val_loss: 97.0613 - val_accuracy: 0.3750\n",
            "Epoch 67/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 70.7909 - accuracy: 0.5594 - val_loss: 45.6338 - val_accuracy: 0.6250\n",
            "Epoch 68/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 53.0214 - accuracy: 0.5219 - val_loss: 4.7926 - val_accuracy: 0.6250\n",
            "Epoch 69/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 51.5686 - accuracy: 0.5719 - val_loss: 119.2549 - val_accuracy: 0.6250\n",
            "Epoch 70/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 56.8331 - accuracy: 0.5156 - val_loss: 128.7746 - val_accuracy: 0.6250\n",
            "Epoch 71/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 119.2992 - accuracy: 0.5469 - val_loss: 211.0904 - val_accuracy: 0.6250\n",
            "Epoch 72/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 104.8836 - accuracy: 0.5531 - val_loss: 88.6897 - val_accuracy: 0.6250\n",
            "Epoch 73/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 123.2588 - accuracy: 0.5156 - val_loss: 90.1897 - val_accuracy: 0.6250\n",
            "Epoch 74/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 142.5728 - accuracy: 0.5031 - val_loss: 217.7512 - val_accuracy: 0.6250\n",
            "Epoch 75/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 93.2535 - accuracy: 0.5781 - val_loss: 136.6111 - val_accuracy: 0.6250\n",
            "Epoch 76/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 81.5247 - accuracy: 0.5594 - val_loss: 27.3510 - val_accuracy: 0.6250\n",
            "Epoch 77/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 23.6166 - accuracy: 0.5906 - val_loss: 24.4203 - val_accuracy: 0.3750\n",
            "Epoch 78/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 34.9604 - accuracy: 0.5344 - val_loss: 6.6406 - val_accuracy: 0.3750\n",
            "Epoch 79/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.3271 - accuracy: 0.5719 - val_loss: 10.5888 - val_accuracy: 0.6250\n",
            "Epoch 80/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.9820 - accuracy: 0.5281 - val_loss: 13.0185 - val_accuracy: 0.6250\n",
            "Epoch 81/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.5241 - accuracy: 0.5344 - val_loss: 3.6464 - val_accuracy: 0.6250\n",
            "Epoch 82/350\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 13.7656 - accuracy: 0.5531 - val_loss: 35.4576 - val_accuracy: 0.6250\n",
            "Epoch 83/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 27.7362 - accuracy: 0.5781 - val_loss: 30.5888 - val_accuracy: 0.6250\n",
            "Epoch 84/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 30.7809 - accuracy: 0.5281 - val_loss: 30.2250 - val_accuracy: 0.6250\n",
            "Epoch 85/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 24.8477 - accuracy: 0.5344 - val_loss: 16.7199 - val_accuracy: 0.6250\n",
            "Epoch 86/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.4524 - accuracy: 0.5344 - val_loss: 12.2419 - val_accuracy: 0.6250\n",
            "Epoch 87/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.6916 - accuracy: 0.5344 - val_loss: 7.0084 - val_accuracy: 0.6250\n",
            "Epoch 88/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6888 - accuracy: 0.5594 - val_loss: 1.5703 - val_accuracy: 0.6250\n",
            "Epoch 89/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.2057 - accuracy: 0.5406 - val_loss: 1.8575 - val_accuracy: 0.6250\n",
            "Epoch 90/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.0949 - accuracy: 0.5969 - val_loss: 26.8191 - val_accuracy: 0.3750\n",
            "Epoch 91/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 15.6841 - accuracy: 0.4906 - val_loss: 7.0108 - val_accuracy: 0.3750\n",
            "Epoch 92/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 14.2768 - accuracy: 0.6094 - val_loss: 28.6586 - val_accuracy: 0.3750\n",
            "Epoch 93/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 13.1720 - accuracy: 0.4969 - val_loss: 0.8069 - val_accuracy: 0.6250\n",
            "Epoch 94/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.1099 - accuracy: 0.6062 - val_loss: 11.1102 - val_accuracy: 0.6250\n",
            "Epoch 95/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.3147 - accuracy: 0.5844 - val_loss: 1.1858 - val_accuracy: 0.6250\n",
            "Epoch 96/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6174 - accuracy: 0.6156 - val_loss: 3.4053 - val_accuracy: 0.6250\n",
            "Epoch 97/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.0766 - accuracy: 0.5469 - val_loss: 8.1774 - val_accuracy: 0.3750\n",
            "Epoch 98/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.5325 - accuracy: 0.5531 - val_loss: 3.9494 - val_accuracy: 0.6250\n",
            "Epoch 99/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.3192 - accuracy: 0.6000 - val_loss: 2.4481 - val_accuracy: 0.3750\n",
            "Epoch 100/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2361 - accuracy: 0.5344 - val_loss: 1.5794 - val_accuracy: 0.7000\n",
            "Epoch 101/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9009 - accuracy: 0.6781 - val_loss: 0.6313 - val_accuracy: 0.7625\n",
            "Epoch 102/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7299 - accuracy: 0.5813 - val_loss: 3.3158 - val_accuracy: 0.6875\n",
            "Epoch 103/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6430 - accuracy: 0.5969 - val_loss: 1.2754 - val_accuracy: 0.7125\n",
            "Epoch 104/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.8998 - accuracy: 0.5938 - val_loss: 3.4633 - val_accuracy: 0.3750\n",
            "Epoch 105/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2720 - accuracy: 0.6094 - val_loss: 1.0434 - val_accuracy: 0.7000\n",
            "Epoch 106/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8568 - accuracy: 0.6594 - val_loss: 1.1461 - val_accuracy: 0.7000\n",
            "Epoch 107/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5613 - accuracy: 0.6031 - val_loss: 0.6643 - val_accuracy: 0.5250\n",
            "Epoch 108/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4347 - accuracy: 0.6594 - val_loss: 4.0663 - val_accuracy: 0.7000\n",
            "Epoch 109/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7502 - accuracy: 0.5969 - val_loss: 0.6187 - val_accuracy: 0.7375\n",
            "Epoch 110/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7252 - accuracy: 0.6906 - val_loss: 0.7668 - val_accuracy: 0.6875\n",
            "Epoch 111/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8328 - accuracy: 0.6656 - val_loss: 1.6124 - val_accuracy: 0.7000\n",
            "Epoch 112/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1208 - accuracy: 0.6562 - val_loss: 1.9826 - val_accuracy: 0.7000\n",
            "Epoch 113/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1518 - accuracy: 0.6906 - val_loss: 0.6256 - val_accuracy: 0.7375\n",
            "Epoch 114/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1764 - accuracy: 0.6438 - val_loss: 0.8078 - val_accuracy: 0.3750\n",
            "Epoch 115/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8949 - accuracy: 0.6031 - val_loss: 1.7020 - val_accuracy: 0.7000\n",
            "Epoch 116/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0485 - accuracy: 0.6781 - val_loss: 0.7034 - val_accuracy: 0.7250\n",
            "Epoch 117/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7617 - accuracy: 0.6781 - val_loss: 0.7903 - val_accuracy: 0.7125\n",
            "Epoch 118/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8085 - accuracy: 0.6938 - val_loss: 0.9900 - val_accuracy: 0.6750\n",
            "Epoch 119/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9125 - accuracy: 0.6469 - val_loss: 0.8525 - val_accuracy: 0.3750\n",
            "Epoch 120/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7096 - accuracy: 0.6812 - val_loss: 0.6993 - val_accuracy: 0.7375\n",
            "Epoch 121/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7662 - accuracy: 0.6938 - val_loss: 0.6627 - val_accuracy: 0.7375\n",
            "Epoch 122/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1495 - accuracy: 0.6219 - val_loss: 1.3627 - val_accuracy: 0.6875\n",
            "Epoch 123/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7594 - accuracy: 0.6781 - val_loss: 0.7239 - val_accuracy: 0.7375\n",
            "Epoch 124/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.6469 - val_loss: 1.0394 - val_accuracy: 0.6750\n",
            "Epoch 125/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7644 - accuracy: 0.7125 - val_loss: 0.6798 - val_accuracy: 0.4625\n",
            "Epoch 126/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1343 - accuracy: 0.6938 - val_loss: 0.9723 - val_accuracy: 0.7125\n",
            "Epoch 127/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3570 - accuracy: 0.6938 - val_loss: 2.8390 - val_accuracy: 0.2875\n",
            "Epoch 128/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5497 - accuracy: 0.6219 - val_loss: 2.6502 - val_accuracy: 0.3000\n",
            "Epoch 129/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3333 - accuracy: 0.6812 - val_loss: 0.7218 - val_accuracy: 0.4500\n",
            "Epoch 130/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3906 - accuracy: 0.6438 - val_loss: 1.5088 - val_accuracy: 0.7125\n",
            "Epoch 131/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1065 - accuracy: 0.6906 - val_loss: 0.9200 - val_accuracy: 0.7375\n",
            "Epoch 132/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8024 - accuracy: 0.6281 - val_loss: 1.0153 - val_accuracy: 0.7375\n",
            "Epoch 133/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8354 - accuracy: 0.7219 - val_loss: 0.8451 - val_accuracy: 0.7625\n",
            "Epoch 134/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9044 - accuracy: 0.6125 - val_loss: 0.9511 - val_accuracy: 0.7375\n",
            "Epoch 135/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7222 - accuracy: 0.6750 - val_loss: 0.8034 - val_accuracy: 0.3750\n",
            "Epoch 136/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7007 - accuracy: 0.6719 - val_loss: 0.8003 - val_accuracy: 0.7625\n",
            "Epoch 137/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8946 - accuracy: 0.7281 - val_loss: 0.9679 - val_accuracy: 0.7375\n",
            "Epoch 138/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.6875 - val_loss: 0.8130 - val_accuracy: 0.7625\n",
            "Epoch 139/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6938 - val_loss: 0.8630 - val_accuracy: 0.7625\n",
            "Epoch 140/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7344 - val_loss: 0.7581 - val_accuracy: 0.7625\n",
            "Epoch 141/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.6406 - val_loss: 0.7049 - val_accuracy: 0.7625\n",
            "Epoch 142/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8506 - accuracy: 0.7344 - val_loss: 0.9507 - val_accuracy: 0.7375\n",
            "Epoch 143/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8649 - accuracy: 0.6125 - val_loss: 0.9782 - val_accuracy: 0.7375\n",
            "Epoch 144/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9702 - accuracy: 0.7063 - val_loss: 1.2993 - val_accuracy: 0.7375\n",
            "Epoch 145/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9080 - accuracy: 0.6625 - val_loss: 0.6465 - val_accuracy: 0.6125\n",
            "Epoch 146/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.7406 - val_loss: 0.6404 - val_accuracy: 0.6500\n",
            "Epoch 147/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.7531 - val_loss: 0.7030 - val_accuracy: 0.7750\n",
            "Epoch 148/350\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.7000 - val_loss: 0.6615 - val_accuracy: 0.7750\n",
            "Epoch 149/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.7406 - val_loss: 0.6906 - val_accuracy: 0.7750\n",
            "Epoch 150/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6732 - accuracy: 0.7063 - val_loss: 0.6911 - val_accuracy: 0.7750\n",
            "Epoch 151/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8707 - accuracy: 0.6625 - val_loss: 0.8983 - val_accuracy: 0.7625\n",
            "Epoch 152/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8705 - accuracy: 0.7000 - val_loss: 1.1579 - val_accuracy: 0.7375\n",
            "Epoch 153/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7791 - accuracy: 0.6219 - val_loss: 0.8822 - val_accuracy: 0.7625\n",
            "Epoch 154/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6977 - accuracy: 0.7344 - val_loss: 0.8291 - val_accuracy: 0.7625\n",
            "Epoch 155/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8354 - accuracy: 0.7156 - val_loss: 1.2011 - val_accuracy: 0.3000\n",
            "Epoch 156/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8779 - accuracy: 0.6313 - val_loss: 0.7100 - val_accuracy: 0.7750\n",
            "Epoch 157/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8104 - accuracy: 0.6906 - val_loss: 0.8584 - val_accuracy: 0.7625\n",
            "Epoch 158/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.7063 - val_loss: 0.7051 - val_accuracy: 0.7750\n",
            "Epoch 159/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.7563 - val_loss: 0.7446 - val_accuracy: 0.3750\n",
            "Epoch 160/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7867 - accuracy: 0.6469 - val_loss: 1.0924 - val_accuracy: 0.7625\n",
            "Epoch 161/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8205 - accuracy: 0.6750 - val_loss: 0.8027 - val_accuracy: 0.3750\n",
            "Epoch 162/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.6687 - val_loss: 1.0260 - val_accuracy: 0.7625\n",
            "Epoch 163/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7736 - accuracy: 0.7063 - val_loss: 0.7502 - val_accuracy: 0.3750\n",
            "Epoch 164/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.6406 - val_loss: 0.7405 - val_accuracy: 0.7625\n",
            "Epoch 165/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.7156 - val_loss: 0.6281 - val_accuracy: 0.7625\n",
            "Epoch 166/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.7812 - val_loss: 0.6628 - val_accuracy: 0.5250\n",
            "Epoch 167/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.7063 - val_loss: 0.6654 - val_accuracy: 0.5250\n",
            "Epoch 168/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8300 - accuracy: 0.6719 - val_loss: 0.8671 - val_accuracy: 0.7625\n",
            "Epoch 169/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.7469 - val_loss: 0.6667 - val_accuracy: 0.7750\n",
            "Epoch 170/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.7437 - val_loss: 0.6615 - val_accuracy: 0.5375\n",
            "Epoch 171/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8353 - accuracy: 0.6875 - val_loss: 1.0437 - val_accuracy: 0.7625\n",
            "Epoch 172/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8891 - accuracy: 0.6875 - val_loss: 1.5501 - val_accuracy: 0.7625\n",
            "Epoch 173/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9896 - accuracy: 0.6844 - val_loss: 0.9451 - val_accuracy: 0.7625\n",
            "Epoch 174/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7790 - accuracy: 0.6906 - val_loss: 0.8255 - val_accuracy: 0.3000\n",
            "Epoch 175/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.7219 - val_loss: 0.7256 - val_accuracy: 0.7750\n",
            "Epoch 176/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.7125 - val_loss: 0.6508 - val_accuracy: 0.7750\n",
            "Epoch 177/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5882 - accuracy: 0.7875 - val_loss: 0.9209 - val_accuracy: 0.7625\n",
            "Epoch 178/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7989 - accuracy: 0.7344 - val_loss: 0.7236 - val_accuracy: 0.3750\n",
            "Epoch 179/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9436 - accuracy: 0.6531 - val_loss: 1.7781 - val_accuracy: 0.2375\n",
            "Epoch 180/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0598 - accuracy: 0.5969 - val_loss: 0.6257 - val_accuracy: 0.7625\n",
            "Epoch 181/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.7906 - val_loss: 0.6579 - val_accuracy: 0.7750\n",
            "Epoch 182/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.7750 - val_loss: 0.6779 - val_accuracy: 0.5375\n",
            "Epoch 183/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.7594 - val_loss: 0.6228 - val_accuracy: 0.7750\n",
            "Epoch 184/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.7937 - val_loss: 0.7104 - val_accuracy: 0.3000\n",
            "Epoch 185/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7486 - accuracy: 0.6594 - val_loss: 0.8136 - val_accuracy: 0.7750\n",
            "Epoch 186/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8575 - accuracy: 0.7375 - val_loss: 0.9342 - val_accuracy: 0.7750\n",
            "Epoch 187/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7452 - accuracy: 0.7344 - val_loss: 0.8857 - val_accuracy: 0.2375\n",
            "Epoch 188/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7134 - accuracy: 0.6469 - val_loss: 0.7788 - val_accuracy: 0.7750\n",
            "Epoch 189/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.7250 - val_loss: 0.6234 - val_accuracy: 0.7750\n",
            "Epoch 190/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5879 - accuracy: 0.7969 - val_loss: 0.6862 - val_accuracy: 0.7750\n",
            "Epoch 191/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.7406 - val_loss: 0.6195 - val_accuracy: 0.7625\n",
            "Epoch 192/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7844 - val_loss: 0.6328 - val_accuracy: 0.7625\n",
            "Epoch 193/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6288 - accuracy: 0.7937 - val_loss: 0.6192 - val_accuracy: 0.7625\n",
            "Epoch 194/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.7969 - val_loss: 0.6397 - val_accuracy: 0.7375\n",
            "Epoch 195/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6844 - val_loss: 0.6423 - val_accuracy: 0.7625\n",
            "Epoch 196/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7380 - accuracy: 0.7312 - val_loss: 0.7546 - val_accuracy: 0.7750\n",
            "Epoch 197/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.7844 - val_loss: 0.6617 - val_accuracy: 0.7625\n",
            "Epoch 198/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.7000 - val_loss: 0.9458 - val_accuracy: 0.7750\n",
            "Epoch 199/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.7063 - val_loss: 0.6213 - val_accuracy: 0.7500\n",
            "Epoch 200/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7469 - val_loss: 0.7857 - val_accuracy: 0.7750\n",
            "Epoch 201/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.7875 - val_loss: 0.6756 - val_accuracy: 0.7625\n",
            "Epoch 202/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5967 - accuracy: 0.7906 - val_loss: 0.6210 - val_accuracy: 0.7625\n",
            "Epoch 203/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.7844 - val_loss: 0.6631 - val_accuracy: 0.7625\n",
            "Epoch 204/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.7812 - val_loss: 0.6290 - val_accuracy: 0.7125\n",
            "Epoch 205/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.7469 - val_loss: 0.6174 - val_accuracy: 0.7375\n",
            "Epoch 206/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.7500 - val_loss: 1.1188 - val_accuracy: 0.2500\n",
            "Epoch 207/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7701 - accuracy: 0.6938 - val_loss: 0.6354 - val_accuracy: 0.6875\n",
            "Epoch 208/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7875 - val_loss: 0.6944 - val_accuracy: 0.7625\n",
            "Epoch 209/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.7312 - val_loss: 0.6915 - val_accuracy: 0.7625\n",
            "Epoch 210/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.7406 - val_loss: 0.7215 - val_accuracy: 0.5625\n",
            "Epoch 211/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.7156 - val_loss: 1.2003 - val_accuracy: 0.7625\n",
            "Epoch 212/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7834 - accuracy: 0.7312 - val_loss: 0.9751 - val_accuracy: 0.7750\n",
            "Epoch 213/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.7906 - val_loss: 0.6736 - val_accuracy: 0.6250\n",
            "Epoch 214/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7111 - accuracy: 0.6906 - val_loss: 0.8798 - val_accuracy: 0.7750\n",
            "Epoch 215/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7376 - accuracy: 0.7125 - val_loss: 0.7693 - val_accuracy: 0.4750\n",
            "Epoch 216/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.7312 - val_loss: 0.8748 - val_accuracy: 0.7750\n",
            "Epoch 217/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.7188 - val_loss: 0.8732 - val_accuracy: 0.7750\n",
            "Epoch 218/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8706 - accuracy: 0.7125 - val_loss: 0.6173 - val_accuracy: 0.7375\n",
            "Epoch 219/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6993 - accuracy: 0.7250 - val_loss: 0.6769 - val_accuracy: 0.7750\n",
            "Epoch 220/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.7812 - val_loss: 0.6191 - val_accuracy: 0.7500\n",
            "Epoch 221/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6256 - accuracy: 0.7781 - val_loss: 0.6890 - val_accuracy: 0.6250\n",
            "Epoch 222/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7582 - accuracy: 0.6687 - val_loss: 1.0861 - val_accuracy: 0.7625\n",
            "Epoch 223/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8171 - accuracy: 0.7156 - val_loss: 0.8239 - val_accuracy: 0.7625\n",
            "Epoch 224/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8172 - accuracy: 0.6906 - val_loss: 0.7593 - val_accuracy: 0.5375\n",
            "Epoch 225/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7207 - accuracy: 0.6781 - val_loss: 0.8728 - val_accuracy: 0.7625\n",
            "Epoch 226/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.7281 - val_loss: 0.6579 - val_accuracy: 0.7750\n",
            "Epoch 227/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.7469 - val_loss: 0.6564 - val_accuracy: 0.6250\n",
            "Epoch 228/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.7312 - val_loss: 1.6535 - val_accuracy: 0.7625\n",
            "Epoch 229/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9094 - accuracy: 0.6906 - val_loss: 0.9999 - val_accuracy: 0.7625\n",
            "Epoch 230/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7442 - accuracy: 0.7219 - val_loss: 0.6575 - val_accuracy: 0.7750\n",
            "Epoch 231/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.7594 - val_loss: 0.6387 - val_accuracy: 0.7625\n",
            "Epoch 232/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7461 - accuracy: 0.7188 - val_loss: 1.4162 - val_accuracy: 0.7625\n",
            "Epoch 233/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0901 - accuracy: 0.6562 - val_loss: 0.7104 - val_accuracy: 0.7750\n",
            "Epoch 234/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.7250 - val_loss: 0.6324 - val_accuracy: 0.7000\n",
            "Epoch 235/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7656 - val_loss: 0.6392 - val_accuracy: 0.7625\n",
            "Epoch 236/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.7906 - val_loss: 0.8355 - val_accuracy: 0.4875\n",
            "Epoch 237/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7320 - accuracy: 0.6906 - val_loss: 0.7254 - val_accuracy: 0.7750\n",
            "Epoch 238/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8765 - accuracy: 0.7500 - val_loss: 0.8750 - val_accuracy: 0.7625\n",
            "Epoch 239/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7559 - accuracy: 0.6750 - val_loss: 0.7612 - val_accuracy: 0.5875\n",
            "Epoch 240/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0299 - accuracy: 0.6281 - val_loss: 0.9474 - val_accuracy: 0.7625\n",
            "Epoch 241/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7407 - accuracy: 0.7281 - val_loss: 0.9763 - val_accuracy: 0.4750\n",
            "Epoch 242/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8612 - accuracy: 0.6750 - val_loss: 0.8912 - val_accuracy: 0.4875\n",
            "Epoch 243/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7274 - accuracy: 0.6938 - val_loss: 0.9417 - val_accuracy: 0.7625\n",
            "Epoch 244/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6816 - accuracy: 0.7156 - val_loss: 0.6367 - val_accuracy: 0.7625\n",
            "Epoch 245/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7291 - accuracy: 0.6938 - val_loss: 1.0614 - val_accuracy: 0.7500\n",
            "Epoch 246/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.7563 - val_loss: 0.6312 - val_accuracy: 0.7625\n",
            "Epoch 247/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6071 - accuracy: 0.7500 - val_loss: 0.7785 - val_accuracy: 0.7625\n",
            "Epoch 248/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6000 - accuracy: 0.7688 - val_loss: 0.6606 - val_accuracy: 0.7625\n",
            "Epoch 249/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.7750 - val_loss: 0.6317 - val_accuracy: 0.7000\n",
            "Epoch 250/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.7625 - val_loss: 0.6181 - val_accuracy: 0.7375\n",
            "Epoch 251/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.7563 - val_loss: 0.6374 - val_accuracy: 0.6250\n",
            "Epoch 252/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7594 - val_loss: 0.6952 - val_accuracy: 0.7750\n",
            "Epoch 253/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.7219 - val_loss: 0.9277 - val_accuracy: 0.7625\n",
            "Epoch 254/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7625 - val_loss: 0.6252 - val_accuracy: 0.7375\n",
            "Epoch 255/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.7469 - val_loss: 0.6202 - val_accuracy: 0.6875\n",
            "Epoch 256/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6605 - accuracy: 0.7531 - val_loss: 0.6181 - val_accuracy: 0.7250\n",
            "Epoch 257/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7113 - accuracy: 0.6750 - val_loss: 0.8135 - val_accuracy: 0.7625\n",
            "Epoch 258/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.7437 - val_loss: 0.6442 - val_accuracy: 0.7625\n",
            "Epoch 259/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.7563 - val_loss: 0.6198 - val_accuracy: 0.7375\n",
            "Epoch 260/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.7688 - val_loss: 0.6449 - val_accuracy: 0.6250\n",
            "Epoch 261/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7043 - accuracy: 0.7219 - val_loss: 1.4324 - val_accuracy: 0.7375\n",
            "Epoch 262/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0786 - accuracy: 0.7031 - val_loss: 1.4886 - val_accuracy: 0.7250\n",
            "Epoch 263/350\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0189 - accuracy: 0.6375 - val_loss: 0.6788 - val_accuracy: 0.6250\n",
            "Epoch 264/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8396 - accuracy: 0.6844 - val_loss: 1.1849 - val_accuracy: 0.7250\n",
            "Epoch 265/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9399 - accuracy: 0.6781 - val_loss: 0.7464 - val_accuracy: 0.7625\n",
            "Epoch 266/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.7406 - val_loss: 0.6717 - val_accuracy: 0.7750\n",
            "Epoch 267/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.7688 - val_loss: 0.6210 - val_accuracy: 0.7375\n",
            "Epoch 268/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.7219 - val_loss: 1.0251 - val_accuracy: 0.7500\n",
            "Epoch 269/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.7250 - val_loss: 0.6507 - val_accuracy: 0.6250\n",
            "Epoch 270/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.7469 - val_loss: 0.9553 - val_accuracy: 0.7625\n",
            "Epoch 271/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6902 - accuracy: 0.7437 - val_loss: 0.6366 - val_accuracy: 0.7625\n",
            "Epoch 272/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.7781 - val_loss: 0.7162 - val_accuracy: 0.7750\n",
            "Epoch 273/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.7594 - val_loss: 0.6655 - val_accuracy: 0.7625\n",
            "Epoch 274/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.7156 - val_loss: 0.8187 - val_accuracy: 0.7625\n",
            "Epoch 275/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.7094 - val_loss: 0.7736 - val_accuracy: 0.7625\n",
            "Epoch 276/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7265 - accuracy: 0.7344 - val_loss: 0.6668 - val_accuracy: 0.6250\n",
            "Epoch 277/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.7281 - val_loss: 0.6403 - val_accuracy: 0.7625\n",
            "Epoch 278/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8702 - accuracy: 0.6562 - val_loss: 0.6455 - val_accuracy: 0.7625\n",
            "Epoch 279/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.7594 - val_loss: 0.6212 - val_accuracy: 0.7000\n",
            "Epoch 280/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.7188 - val_loss: 0.6961 - val_accuracy: 0.7750\n",
            "Epoch 281/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.7437 - val_loss: 0.6483 - val_accuracy: 0.7625\n",
            "Epoch 282/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7407 - accuracy: 0.7063 - val_loss: 1.4904 - val_accuracy: 0.6875\n",
            "Epoch 283/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.6844 - val_loss: 2.0121 - val_accuracy: 0.6625\n",
            "Epoch 284/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1767 - accuracy: 0.6531 - val_loss: 0.8178 - val_accuracy: 0.7625\n",
            "Epoch 285/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6641 - accuracy: 0.7344 - val_loss: 0.6802 - val_accuracy: 0.7750\n",
            "Epoch 286/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.7031 - val_loss: 0.6300 - val_accuracy: 0.7375\n",
            "Epoch 287/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9041 - accuracy: 0.6687 - val_loss: 1.0110 - val_accuracy: 0.7500\n",
            "Epoch 288/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.7344 - val_loss: 0.6549 - val_accuracy: 0.7625\n",
            "Epoch 289/350\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6144 - accuracy: 0.7312 - val_loss: 0.6512 - val_accuracy: 0.7625\n",
            "Epoch 290/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.7688 - val_loss: 0.6195 - val_accuracy: 0.6750\n",
            "Epoch 291/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.7594 - val_loss: 0.6310 - val_accuracy: 0.6625\n",
            "Epoch 292/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7563 - accuracy: 0.7219 - val_loss: 0.6915 - val_accuracy: 0.7625\n",
            "Epoch 293/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7715 - accuracy: 0.6687 - val_loss: 0.7447 - val_accuracy: 0.7625\n",
            "Epoch 294/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7112 - accuracy: 0.7375 - val_loss: 1.0435 - val_accuracy: 0.5125\n",
            "Epoch 295/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7337 - accuracy: 0.7125 - val_loss: 0.6585 - val_accuracy: 0.7625\n",
            "Epoch 296/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7684 - accuracy: 0.7063 - val_loss: 1.4621 - val_accuracy: 0.6625\n",
            "Epoch 297/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9091 - accuracy: 0.7063 - val_loss: 0.6219 - val_accuracy: 0.7375\n",
            "Epoch 298/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9428 - accuracy: 0.6750 - val_loss: 1.0977 - val_accuracy: 0.4875\n",
            "Epoch 299/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8480 - accuracy: 0.6375 - val_loss: 1.3766 - val_accuracy: 0.6875\n",
            "Epoch 300/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1764 - accuracy: 0.6687 - val_loss: 1.5551 - val_accuracy: 0.6875\n",
            "Epoch 301/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2068 - accuracy: 0.6187 - val_loss: 0.7122 - val_accuracy: 0.6250\n",
            "Epoch 302/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7636 - accuracy: 0.7281 - val_loss: 1.0986 - val_accuracy: 0.7500\n",
            "Epoch 303/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8126 - accuracy: 0.7156 - val_loss: 1.1425 - val_accuracy: 0.5250\n",
            "Epoch 304/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7264 - accuracy: 0.7156 - val_loss: 0.6260 - val_accuracy: 0.7000\n",
            "Epoch 305/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5995 - accuracy: 0.7531 - val_loss: 0.6224 - val_accuracy: 0.7125\n",
            "Epoch 306/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.7375 - val_loss: 0.8604 - val_accuracy: 0.5750\n",
            "Epoch 307/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6872 - accuracy: 0.7219 - val_loss: 0.6265 - val_accuracy: 0.7000\n",
            "Epoch 308/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6534 - accuracy: 0.6969 - val_loss: 0.8480 - val_accuracy: 0.7625\n",
            "Epoch 309/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7635 - accuracy: 0.7219 - val_loss: 0.8810 - val_accuracy: 0.5750\n",
            "Epoch 310/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7679 - accuracy: 0.7156 - val_loss: 0.6218 - val_accuracy: 0.7125\n",
            "Epoch 311/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9966 - accuracy: 0.6656 - val_loss: 0.8717 - val_accuracy: 0.7500\n",
            "Epoch 312/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7463 - accuracy: 0.7031 - val_loss: 1.2271 - val_accuracy: 0.6875\n",
            "Epoch 313/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8120 - accuracy: 0.6906 - val_loss: 0.6481 - val_accuracy: 0.7625\n",
            "Epoch 314/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0605 - accuracy: 0.6531 - val_loss: 0.6401 - val_accuracy: 0.7375\n",
            "Epoch 315/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8707 - accuracy: 0.6875 - val_loss: 0.6372 - val_accuracy: 0.6250\n",
            "Epoch 316/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0717 - accuracy: 0.6594 - val_loss: 0.9161 - val_accuracy: 0.5750\n",
            "Epoch 317/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7508 - accuracy: 0.6781 - val_loss: 0.7087 - val_accuracy: 0.7750\n",
            "Epoch 318/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7205 - accuracy: 0.7406 - val_loss: 0.6501 - val_accuracy: 0.7375\n",
            "Epoch 319/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1933 - accuracy: 0.6812 - val_loss: 1.8733 - val_accuracy: 0.4750\n",
            "Epoch 320/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2581 - accuracy: 0.6625 - val_loss: 0.7129 - val_accuracy: 0.7625\n",
            "Epoch 321/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.7531 - val_loss: 0.7039 - val_accuracy: 0.6250\n",
            "Epoch 322/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.7312 - val_loss: 0.6364 - val_accuracy: 0.6500\n",
            "Epoch 323/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7344 - val_loss: 0.9944 - val_accuracy: 0.7625\n",
            "Epoch 324/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7215 - accuracy: 0.7250 - val_loss: 0.6404 - val_accuracy: 0.6250\n",
            "Epoch 325/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.7344 - val_loss: 0.7004 - val_accuracy: 0.7750\n",
            "Epoch 326/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8061 - accuracy: 0.7406 - val_loss: 0.7343 - val_accuracy: 0.6250\n",
            "Epoch 327/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0904 - accuracy: 0.6187 - val_loss: 0.6469 - val_accuracy: 0.7375\n",
            "Epoch 328/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8054 - accuracy: 0.7125 - val_loss: 0.6629 - val_accuracy: 0.7625\n",
            "Epoch 329/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.7469 - val_loss: 0.7058 - val_accuracy: 0.7750\n",
            "Epoch 330/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6210 - accuracy: 0.7531 - val_loss: 0.6404 - val_accuracy: 0.7375\n",
            "Epoch 331/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.7281 - val_loss: 0.6268 - val_accuracy: 0.7000\n",
            "Epoch 332/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.7344 - val_loss: 0.6561 - val_accuracy: 0.7625\n",
            "Epoch 333/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8626 - accuracy: 0.7250 - val_loss: 0.7551 - val_accuracy: 0.5875\n",
            "Epoch 334/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7060 - accuracy: 0.7156 - val_loss: 0.6553 - val_accuracy: 0.6250\n",
            "Epoch 335/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8984 - accuracy: 0.6719 - val_loss: 0.8053 - val_accuracy: 0.7625\n",
            "Epoch 336/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3263 - accuracy: 0.6281 - val_loss: 1.7965 - val_accuracy: 0.4625\n",
            "Epoch 337/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3120 - accuracy: 0.6313 - val_loss: 1.1805 - val_accuracy: 0.7500\n",
            "Epoch 338/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1094 - accuracy: 0.6938 - val_loss: 2.1169 - val_accuracy: 0.6625\n",
            "Epoch 339/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3405 - accuracy: 0.6656 - val_loss: 2.4252 - val_accuracy: 0.6625\n",
            "Epoch 340/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8743 - accuracy: 0.7250 - val_loss: 0.6265 - val_accuracy: 0.7000\n",
            "Epoch 341/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5843 - accuracy: 0.7688 - val_loss: 0.8337 - val_accuracy: 0.7625\n",
            "Epoch 342/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.7406 - val_loss: 0.9199 - val_accuracy: 0.7500\n",
            "Epoch 343/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8049 - accuracy: 0.7125 - val_loss: 0.9220 - val_accuracy: 0.7500\n",
            "Epoch 344/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8359 - accuracy: 0.7250 - val_loss: 0.6284 - val_accuracy: 0.7000\n",
            "Epoch 345/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.7219 - val_loss: 0.9042 - val_accuracy: 0.7500\n",
            "Epoch 346/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9633 - accuracy: 0.7000 - val_loss: 1.6453 - val_accuracy: 0.4750\n",
            "Epoch 347/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9940 - accuracy: 0.6812 - val_loss: 0.8372 - val_accuracy: 0.7625\n",
            "Epoch 348/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.7281 - val_loss: 0.6752 - val_accuracy: 0.7625\n",
            "Epoch 349/350\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7959 - accuracy: 0.7219 - val_loss: 0.6221 - val_accuracy: 0.6750\n",
            "Epoch 350/350\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8802 - accuracy: 0.6875 - val_loss: 1.9271 - val_accuracy: 0.6625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe106e251d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ordud2cMXfaZ"
      },
      "source": [
        "predict=model.predict(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2pl9EWmf-jH",
        "outputId": "d515d13b-e368-405d-ffe9-b01d637f72f3"
      },
      "source": [
        "predict[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.83250916, 0.16749083], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNCufsgigVZb",
        "outputId": "cb6c70a0-e33d-42f8-9a1e-22de0169a6c9"
      },
      "source": [
        "np.argmax(predict[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzMMxexDgnFe",
        "outputId": "0443186a-587d-43c1-9f72-3d34a41e44b3"
      },
      "source": [
        "np.argmax(predict[7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    }
  ]
}